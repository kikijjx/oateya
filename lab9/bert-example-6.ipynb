{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024729,
     "end_time": "2020-09-24T07:52:26.088870",
     "exception": false,
     "start_time": "2020-09-24T07:52:26.064141",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**PART 1: Получение устройства для расчётов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-09-24T07:52:26.145299Z",
     "iopub.status.busy": "2020-09-24T07:52:26.144428Z",
     "iopub.status.idle": "2020-09-24T07:52:27.303258Z",
     "shell.execute_reply": "2020-09-24T07:52:27.303867Z"
    },
    "papermill": {
     "duration": 1.191908,
     "end_time": "2020-09-24T07:52:27.304095",
     "exception": false,
     "start_time": "2020-09-24T07:52:26.112187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_device\u001b[39m():\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Если в системе есть GPU ...\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m      7\u001b[0m         \u001b[38;5;66;03m# Тогда говорим PyTorch использовать GPU.\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def get_device():\n",
    "    # Если в системе есть GPU ...\n",
    "    if torch.cuda.is_available():\n",
    "        # Тогда говорим PyTorch использовать GPU.\n",
    "        device = torch.device(\"cuda\")\n",
    "        print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "        print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "    # Если нет GPU, то считаем на обычном процессоре ...\n",
    "    else:\n",
    "        print('No GPU available, using the CPU instead.')\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device\n",
    "\n",
    "\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023068,
     "end_time": "2020-09-24T07:52:27.351318",
     "exception": false,
     "start_time": "2020-09-24T07:52:27.328250",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**PART 2: Загрузка датасета из интернета**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-09-24T07:52:27.415028Z",
     "iopub.status.busy": "2020-09-24T07:52:27.414131Z",
     "iopub.status.idle": "2020-09-24T07:52:40.687397Z",
     "shell.execute_reply": "2020-09-24T07:52:40.686541Z"
    },
    "papermill": {
     "duration": 13.311051,
     "end_time": "2020-09-24T07:52:40.687535",
     "exception": false,
     "start_time": "2020-09-24T07:52:27.376484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wget in c:\\users\\nikita\\desktop\\vscode\\oateya\\lab9\\venv\\lib\\site-packages (3.2)Downloading dataset...\n",
      "\n",
      "Complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\nikita\\desktop\\vscode\\oateya\\lab9\\venv\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install wget\n",
    "\n",
    "def download_dataset():\n",
    "    import wget\n",
    "    import os\n",
    "    import zipfile\n",
    "\n",
    "    print('Downloading dataset...')\n",
    "    # URL до zip-файла который содержит датасет.\n",
    "    url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'\n",
    "    out_file = './cola_public_1.1.zip'\n",
    "\n",
    "    # Скачиваем файл (только в случае если не скачали раньше)\n",
    "    if not os.path.exists(out_file):\n",
    "        wget.download(url, out_file)\n",
    "    # Unzip\n",
    "    if not os.path.exists('./cola_public/'):\n",
    "        with zipfile.ZipFile(out_file, 'r') as zip_ref:\n",
    "            zip_ref.extractall(os.path.dirname(out_file))\n",
    "    print('Complete')\n",
    "\n",
    "\n",
    "download_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027176,
     "end_time": "2020-09-24T07:52:40.742472",
     "exception": false,
     "start_time": "2020-09-24T07:52:40.715296",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**PART 3: Получение предложений и разметки к ним**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-24T07:52:40.811289Z",
     "iopub.status.busy": "2020-09-24T07:52:40.810468Z",
     "iopub.status.idle": "2020-09-24T07:52:40.875379Z",
     "shell.execute_reply": "2020-09-24T07:52:40.876151Z"
    },
    "papermill": {
     "duration": 0.10607,
     "end_time": "2020-09-24T07:52:40.876321",
     "exception": false,
     "start_time": "2020-09-24T07:52:40.770251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 8,551\n",
      "\n",
      "     sentence_source  label label_notes  \\\n",
      "1066            bc01      1         NaN   \n",
      "7953            ad03      1         NaN   \n",
      "6661            m_02      1         NaN   \n",
      "7474           sks13      0           *   \n",
      "2380            l-93      1         NaN   \n",
      "8281            ad03      1         NaN   \n",
      "5752            c_13      1         NaN   \n",
      "389             bc01      1         NaN   \n",
      "2740            l-93      1         NaN   \n",
      "4205            ks08      1         NaN   \n",
      "\n",
      "                                               sentence  \n",
      "1066            John will see which picture of himself?  \n",
      "7953                  What I said was that we would go.  \n",
      "6661                  The mouse was out the cheese box.  \n",
      "7474                                 her will the race.  \n",
      "2380      Mark terrified me with his single mindedness.  \n",
      "8281  Poseidon appears to have turned out to have left.  \n",
      "5752      Susan rode a bright blue train from New York.  \n",
      "389                             He has often seen Mary.  \n",
      "2740           Carmen bought a dress at Bloomingdale's.  \n",
      "4205  None of his customary excuses suffices Edgar now.  \n",
      "                                               sentence  label\n",
      "8067                                   Anson put a book      0\n",
      "2706                     The package drove to New York.      0\n",
      "185   The fatter he goes to a doctor when he gets th...      0\n",
      "5958              I inquired for John to like his beer.      0\n",
      "6196                         Who did you like and John?      0\n"
     ]
    }
   ],
   "source": [
    "def get_sentences_and_labels():\n",
    "    import pandas as pd\n",
    "\n",
    "    # Загружаем dataset в pandas dataframe.\n",
    "    df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
    "\n",
    "    # Выводим число тренировочных предложений.\n",
    "    print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
    "\n",
    "    # Выводим случайные 10 рядов из таблички.\n",
    "    print(df.sample(10))\n",
    "\n",
    "    # Выводим 5 грамматически неверных предложений.\n",
    "    print(df.loc[df.label == 0].sample(5)[['sentence', 'label']])\n",
    "\n",
    "    sentences = df['sentence'].values\n",
    "    labels = df['label'].values\n",
    "\n",
    "    # Возвращаем все предложения и разметку к ним.\n",
    "    return sentences, labels\n",
    "\n",
    "\n",
    "sentences, labels = get_sentences_and_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.027972,
     "end_time": "2020-09-24T07:52:40.932704",
     "exception": false,
     "start_time": "2020-09-24T07:52:40.904732",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**PART 4: Получение токенайзера и тестирование его работы**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-24T07:52:40.999856Z",
     "iopub.status.busy": "2020-09-24T07:52:40.998990Z",
     "iopub.status.idle": "2020-09-24T07:52:50.803706Z",
     "shell.execute_reply": "2020-09-24T07:52:50.802922Z"
    },
    "papermill": {
     "duration": 9.841381,
     "end_time": "2020-09-24T07:52:50.803836",
     "exception": false,
     "start_time": "2020-09-24T07:52:40.962455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nikita\\Desktop\\vscode\\oateya\\lab9\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n",
      "Original: Our friends won't buy this analysis, let alone the next one we propose.\n",
      "Tokenized:  ['our', 'friends', 'won', \"'\", 't', 'buy', 'this', 'analysis', ',', 'let', 'alone', 'the', 'next', 'one', 'we', 'propose', '.']\n",
      "Token IDs:  [2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012]\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "sentence_number = 0\n",
    "# Напечатать оригинальное предложение.\n",
    "print('Original:', sentences[sentence_number])\n",
    "# Напечатать предложение разбитое на отдельные токены из словаря.\n",
    "print('Tokenized: ', tokenizer.tokenize(sentences[sentence_number]))\n",
    "# Напечатать предложение разбитое на номера токенов в словаре.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[sentence_number])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030633,
     "end_time": "2020-09-24T07:52:50.865467",
     "exception": false,
     "start_time": "2020-09-24T07:52:50.834834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**PART 5: Подсчет максимальной длины текста в датасете (с учетом токенизации и специальных токенов)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-24T07:52:50.961444Z",
     "iopub.status.busy": "2020-09-24T07:52:50.950841Z",
     "iopub.status.idle": "2020-09-24T07:52:54.475152Z",
     "shell.execute_reply": "2020-09-24T07:52:54.474296Z"
    },
    "papermill": {
     "duration": 3.57935,
     "end_time": "2020-09-24T07:52:54.475288",
     "exception": false,
     "start_time": "2020-09-24T07:52:50.895938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  47\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "# Считаем какой максимальный размер имеет предложение разбитое на токены и разбавленное спец. токенами.\n",
    "for sent in sentences:\n",
    "    # Токенизируем текст и добавляем `[CLS]` и `[SEP]` токены.\n",
    "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "    # Обновляем максимум.\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "print('Max sentence length: ', max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030831,
     "end_time": "2020-09-24T07:52:54.537009",
     "exception": false,
     "start_time": "2020-09-24T07:52:54.506178",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**PART 6: Токенизация всех предложений в датасете (полноценно)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-24T07:52:54.616974Z",
     "iopub.status.busy": "2020-09-24T07:52:54.616084Z",
     "iopub.status.idle": "2020-09-24T07:53:00.281196Z",
     "shell.execute_reply": "2020-09-24T07:53:00.280401Z"
    },
    "papermill": {
     "duration": 5.713171,
     "end_time": "2020-09-24T07:53:00.281325",
     "exception": false,
     "start_time": "2020-09-24T07:52:54.568154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "c:\\Users\\nikita\\Desktop\\vscode\\oateya\\lab9\\venv\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2834: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
      "Token IDs: tensor([  101,  2256,  2814,  2180,  1005,  1056,  4965,  2023,  4106,  1010,\n",
      "         2292,  2894,  1996,  2279,  2028,  2057, 16599,  1012,   102,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0])\n",
      "Attention masks: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "Labels: tensor(1)\n"
     ]
    }
   ],
   "source": [
    "input_ids, attention_masks = [], []\n",
    "\n",
    "# Для всех предложений...\n",
    "for sent in sentences:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        sent,  # Текст для токенизации.\n",
    "        add_special_tokens=True,  # Добавляем '[CLS]' и '[SEP]'\n",
    "        max_length=64,  # Дополняем [PAD] или обрезаем текст до 64 токенов.\n",
    "        pad_to_max_length=True,\n",
    "        return_attention_mask=True,  # Возвращаем также attn. masks.\n",
    "        return_tensors='pt',  # Возвращаем в виде тензоров pytorch.\n",
    "    )\n",
    "\n",
    "    # Добавляем токенизированное предложение в список\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    # И добавляем attention mask в список\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Конвертируем списки в полноценные тензоры Pytorch.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Печатаем предложение с номером 0, его токены (теперь в виде номеров в словаре) и.т.д.\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])\n",
    "print('Attention masks:', attention_masks[0])\n",
    "print('Labels:', labels[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.031279,
     "end_time": "2020-09-24T07:53:00.347573",
     "exception": false,
     "start_time": "2020-09-24T07:53:00.316294",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**PART 7: Разделение данных на тренировочные и валидационные**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-24T07:53:00.421588Z",
     "iopub.status.busy": "2020-09-24T07:53:00.420648Z",
     "iopub.status.idle": "2020-09-24T07:53:00.430709Z",
     "shell.execute_reply": "2020-09-24T07:53:00.429934Z"
    },
    "papermill": {
     "duration": 0.051242,
     "end_time": "2020-09-24T07:53:00.430845",
     "exception": false,
     "start_time": "2020-09-24T07:53:00.379603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7,695 training samples\n",
      "  856 validation samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "# Объединяем все тренировочные данные в один TensorDataset.\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# Делаем разделение случайное разбиение 90% - тренировка 10% - валидация.\n",
    "\n",
    "# Считаем число данных для тренировки и для валидации.\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Разбиваем датасет с учетом посчитанного количества.\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.031899,
     "end_time": "2020-09-24T07:53:00.499267",
     "exception": false,
     "start_time": "2020-09-24T07:53:00.467368",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**PART 8: Создание загрузчиков данных (Data Loaders)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-24T07:53:00.572118Z",
     "iopub.status.busy": "2020-09-24T07:53:00.571157Z",
     "iopub.status.idle": "2020-09-24T07:53:00.573887Z",
     "shell.execute_reply": "2020-09-24T07:53:00.574490Z"
    },
    "papermill": {
     "duration": 0.043393,
     "end_time": "2020-09-24T07:53:00.574670",
     "exception": false,
     "start_time": "2020-09-24T07:53:00.531277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader, RandomSampler, SequentialSampler\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# DataLoader должен знать размер батча для тренировки мы задаем его здесь.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Размер батча – это сколько текстов будет подаваться на сеть для вычисления градиентов\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Авторы BERT предлагают ставить его 16 или 32. \u001b[39;00m\n\u001b[0;32m      6\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# DataLoader должен знать размер батча для тренировки мы задаем его здесь.\n",
    "# Размер батча – это сколько текстов будет подаваться на сеть для вычисления градиентов\n",
    "# Авторы BERT предлагают ставить его 16 или 32. \n",
    "batch_size = 32\n",
    "\n",
    "# Создаем отдельные DataLoaders для наших тренировочного и валидационного наборов\n",
    "\n",
    "# Для тренировки мы берем тексты в случайном порядке.\n",
    "train_dataloader = DataLoader(\n",
    "        train_dataset,  # Тренировочный набор данных.\n",
    "        sampler = RandomSampler(train_dataset), # Выбираем батчи случайно\n",
    "        batch_size = batch_size # Тренируем с таким размером батча.\n",
    ")\n",
    "\n",
    "# Для валидации порядок не важен, поэтому зачитываем их последовательно.\n",
    "validation_dataloader = DataLoader(\n",
    "        val_dataset, # Валидационный набор данных.\n",
    "        sampler = SequentialSampler(val_dataset), # Выбираем батчи последовательно.\n",
    "        batch_size = batch_size # Считаем качество модели с таким размером батча.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032216,
     "end_time": "2020-09-24T07:53:00.639164",
     "exception": false,
     "start_time": "2020-09-24T07:53:00.606948",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**PART 9: Создаем модель BERT и выводим структуру её слоёв для примера**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-24T07:53:00.719479Z",
     "iopub.status.busy": "2020-09-24T07:53:00.718612Z",
     "iopub.status.idle": "2020-09-24T07:53:19.614821Z",
     "shell.execute_reply": "2020-09-24T07:53:19.615561Z"
    },
    "papermill": {
     "duration": 18.944514,
     "end_time": "2020-09-24T07:53:19.615789",
     "exception": false,
     "start_time": "2020-09-24T07:53:00.671275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (2, 768)\n",
      "classifier.bias                                                 (2,)\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "# Загружаем BertForSequenceClassification. Это предобученная модель BERT с одиночным полносвязным слоем для классификации\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", # Используем 12-слойную модель BERT, со словарем без регистра.\n",
    "    num_labels = 2, # Количество выходных слоёв – 2 для бинарной классификации. Можно увеличить для мультиклассовой классификации.\n",
    "    output_attentions = False, # Будет ли модель возвращать веса для attention-слоёв. В нашем случае нет.\n",
    "    output_hidden_states = False, # Будет ли модель возвращать состояние всех скрытых слоёв. В нашем случае нет.\n",
    ")\n",
    "\n",
    "# Здесь мы говорим PyTorch что хотим тренировать модель на GPU.\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "# Получаем все параметры модели как список кортежей и выводим сводную информацию по модели.\n",
    "params = list(model.named_parameters())\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "print('==== Embedding Layer ====\\n')\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.034581,
     "end_time": "2020-09-24T07:53:19.686753",
     "exception": false,
     "start_time": "2020-09-24T07:53:19.652172",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**PART 10: Создаем оптимизатор Adam, задаем количество эпох для тренировки и создаем планировщик learning rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-24T07:53:19.766726Z",
     "iopub.status.busy": "2020-09-24T07:53:19.765592Z",
     "iopub.status.idle": "2020-09-24T07:53:19.769270Z",
     "shell.execute_reply": "2020-09-24T07:53:19.768604Z"
    },
    "papermill": {
     "duration": 0.047884,
     "end_time": "2020-09-24T07:53:19.769404",
     "exception": false,
     "start_time": "2020-09-24T07:53:19.721520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nikita\\Desktop\\vscode\\oateya\\lab9\\venv\\lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "    lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "    eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    ")\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Количество эпох для тренировки. Авторы BERT рекомендуют от 2 до 4.\n",
    "# Мы выбираем 4, но увидим позже, что это приводит к оверфиту на тренировочные данные.\n",
    "epochs = 1\n",
    "\n",
    "# Общее число шагов тренировки равно [количество батчей] x [число эпох].\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Создаем планировщик learning rate (LR). LR будет плавно уменьшаться в процессе тренировки\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.035024,
     "end_time": "2020-09-24T07:53:19.839960",
     "exception": false,
     "start_time": "2020-09-24T07:53:19.804936",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**PART 11: Две полезные функции: расчёт точности и вывод затраченного времени**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-24T07:53:19.920578Z",
     "iopub.status.busy": "2020-09-24T07:53:19.919428Z",
     "iopub.status.idle": "2020-09-24T07:53:19.923149Z",
     "shell.execute_reply": "2020-09-24T07:53:19.922520Z"
    },
    "papermill": {
     "duration": 0.048268,
     "end_time": "2020-09-24T07:53:19.923282",
     "exception": false,
     "start_time": "2020-09-24T07:53:19.875014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Функция для расчёта точности. Сравниваются предсказания и реальная разметка к данным\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import random \n",
    "\n",
    "# На вход время в секундах и возвращается строка в формате hh:mm:ss\n",
    "def format_time(elapsed):\n",
    "    # Округляем до ближайшей секунды.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "\n",
    "    # Форматируем как hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.034843,
     "end_time": "2020-09-24T07:53:19.994309",
     "exception": false,
     "start_time": "2020-09-24T07:53:19.959466",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**PART 12: Выполняем один проход обучения по всем тренировочным данным.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-24T07:53:20.082209Z",
     "iopub.status.busy": "2020-09-24T07:53:20.080876Z",
     "iopub.status.idle": "2020-09-24T07:53:20.084601Z",
     "shell.execute_reply": "2020-09-24T07:53:20.083823Z"
    },
    "papermill": {
     "duration": 0.055318,
     "end_time": "2020-09-24T07:53:20.084769",
     "exception": false,
     "start_time": "2020-09-24T07:53:20.029451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_step(device, model, train_dataloader, optimizer, scheduler):\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "    # Переводим модель в режим тренировки.\n",
    "    model.train()\n",
    "\n",
    "    # Для каждого батча из тренировочных данных...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Извлекаем все компоненты из полученного батча\n",
    "        b_input_ids, b_input_mask, b_labels = batch[0].to(device), batch[1].to(device), batch[2].to(device)\n",
    "        # Очищаем все ранее посчитанные градиенты (это важно)\n",
    "        model.zero_grad()\n",
    "        # Выполняем прямой проход по данным\n",
    "        #loss, logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "        # Накапливаем тренировочную функцию потерь по всем батчам\n",
    "        total_train_loss += loss.item()\n",
    "        # Выполняем обратное распространение ошибки что бы посчитать градиенты.\n",
    "        loss.backward()\n",
    "        # Ограничиваем максимальный размер градиента до 1.0. Это позволяет избежать проблемы \"exploding gradients\".\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        # Обновляем параметры модели используя рассчитанные градиенты с помощью выбранного оптимизатора и текущего learning rate.\n",
    "        optimizer.step()\n",
    "        # Обновляем learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Считаем среднее значение функции потерь по всем батчам.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    # Сохраняем время тренировки одной эпохи.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "    return avg_train_loss, training_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.035562,
     "end_time": "2020-09-24T07:53:20.155970",
     "exception": false,
     "start_time": "2020-09-24T07:53:20.120408",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**PART 14: Выполняем один проход подсчёта метрик на валидации**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-24T07:53:20.231624Z",
     "iopub.status.busy": "2020-09-24T07:53:20.230815Z",
     "iopub.status.idle": "2020-09-24T07:53:20.245680Z",
     "shell.execute_reply": "2020-09-24T07:53:20.244861Z"
    },
    "papermill": {
     "duration": 0.053804,
     "end_time": "2020-09-24T07:53:20.245817",
     "exception": false,
     "start_time": "2020-09-24T07:53:20.192013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validation_step(device, model, validation_dataloader):\n",
    "    print(\"Running Validation...\")\n",
    "    t0 = time.time()\n",
    "    # Переводим модель в режим evaluation – некоторые слои, например dropout ведут себя по другому.\n",
    "    model.eval()\n",
    "\n",
    "    # Переменные для подсчёта функции потерь и точности\n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    # Прогоняем все данные из валидации\n",
    "    for batch in validation_dataloader:\n",
    "        # Извлекаем все компоненты из полученного батча.\n",
    "        b_input_ids, b_input_mask, b_labels = batch[0].to(device), batch[1].to(device), batch[2].to(device)\n",
    "\n",
    "        # Говорим pytorch что нам не нужен вычислительный граф для подсчёта градиентов (всё будет работать намного быстрее)\n",
    "        with torch.no_grad():\n",
    "            # Прямой проход по нейронной сети и получение выходных значений.\n",
    "            outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "            #(loss, logits) = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "\n",
    "        # Накапливаем значение функции потерь для валидации.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Переносим значения с GPU на CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "        # Считаем точность для отдельного батча с текстами и накапливаем значения.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "\n",
    "    # Выводим точность для всех валидационных данных.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Считаем среднюю функцию потерь для всех батчей.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    # Измеряем как долго считалась валидация.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "    return avg_val_loss, avg_val_accuracy, validation_time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.035237,
     "end_time": "2020-09-24T07:53:20.316644",
     "exception": false,
     "start_time": "2020-09-24T07:53:20.281407",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**PART 15: Основной цикл тренировки**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-24T07:53:20.401215Z",
     "iopub.status.busy": "2020-09-24T07:53:20.400265Z",
     "iopub.status.idle": "2020-09-24T08:34:10.368474Z",
     "shell.execute_reply": "2020-09-24T08:34:10.369175Z"
    },
    "papermill": {
     "duration": 2450.01733,
     "end_time": "2020-09-24T08:34:10.369385",
     "exception": false,
     "start_time": "2020-09-24T07:53:20.352055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Epoch 1 / 1 ========\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'item'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Для каждой эпохи...\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch_i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, epochs):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Запустить одну эпоху тренировки (следующий слайд) \u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m     avg_train_loss, training_time \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Запустить валидацию что бы проверить качество модели на данном этапе (следующий слайд)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     avg_val_loss, avg_val_accuracy, validation_time \u001b[38;5;241m=\u001b[39m validation_step(device, model, validation_dataloader)\n",
      "Cell \u001b[1;32mIn[17], line 21\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(device, model, train_dataloader, optimizer, scheduler)\u001b[0m\n\u001b[0;32m     19\u001b[0m loss, logits \u001b[38;5;241m=\u001b[39m model(b_input_ids, token_type_ids\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, attention_mask\u001b[38;5;241m=\u001b[39mb_input_mask, labels\u001b[38;5;241m=\u001b[39mb_labels)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Накапливаем тренировочную функцию потерь по всем батчам\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m total_train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m()\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Выполняем обратное распространение ошибки что бы посчитать градиенты.\u001b[39;00m\n\u001b[0;32m     23\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'item'"
     ]
    }
   ],
   "source": [
    "# В этой переменной сохраним всякую статистику по тренировке: точность, функцию цены (потерь) и время выполнения.\n",
    "training_stats = []\n",
    "# Переменная что бы измерить время всей тренировки.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# Для каждой эпохи...\n",
    "for epoch_i in range(0, epochs):\n",
    "    # Запустить одну эпоху тренировки (следующий слайд) \n",
    "    avg_train_loss, training_time = train_step(device, model, train_dataloader, optimizer, scheduler)\n",
    "    # Запустить валидацию что бы проверить качество модели на данном этапе (следующий слайд)\n",
    "    avg_val_loss, avg_val_accuracy, validation_time = validation_step(device, model, validation_dataloader)\n",
    "\n",
    "    # Сохраняем статистику тренировки на данной эпохе.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'Epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Validation Loss': avg_val_loss,\n",
    "            'Validation Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"Training complete! Total training took {:} (hh:mm:ss)\".format(format_time(time.time() - total_t0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.039026,
     "end_time": "2020-09-24T08:34:10.448066",
     "exception": false,
     "start_time": "2020-09-24T08:34:10.409040",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**PART 15: Сохранение модели**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-24T08:34:10.535888Z",
     "iopub.status.busy": "2020-09-24T08:34:10.534793Z",
     "iopub.status.idle": "2020-09-24T08:34:11.168553Z",
     "shell.execute_reply": "2020-09-24T08:34:11.169110Z"
    },
    "papermill": {
     "duration": 0.681941,
     "end_time": "2020-09-24T08:34:11.169278",
     "exception": false,
     "start_time": "2020-09-24T08:34:10.487337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to ./model_save/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./model_save/vocab.txt',\n",
       " './model_save/special_tokens_map.json',\n",
       " './model_save/added_tokens.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Задаем выходную директорию\n",
    "output_dir = './model_save/'\n",
    "# Если она не существует создаем её\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "print(\"Saving model to %s\" % output_dir)\n",
    "\n",
    "# Сохраняем натренированную модель и её токенайзер используя `save_pretrained()`.\n",
    "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.040021,
     "end_time": "2020-09-24T08:34:11.249563",
     "exception": false,
     "start_time": "2020-09-24T08:34:11.209542",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**PART 16: Восстановление модели из сохраненной копии**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-24T08:34:11.336951Z",
     "iopub.status.busy": "2020-09-24T08:34:11.336163Z",
     "iopub.status.idle": "2020-09-24T08:34:14.850008Z",
     "shell.execute_reply": "2020-09-24T08:34:14.849054Z"
    },
    "papermill": {
     "duration": 3.560317,
     "end_time": "2020-09-24T08:34:14.850162",
     "exception": false,
     "start_time": "2020-09-24T08:34:11.289845",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "# Загружаем натренированную модель и её словарь\n",
    "model = BertForSequenceClassification.from_pretrained(output_dir)\n",
    "tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
    "\n",
    "# Отправляем модель на GPU.\n",
    "if torch.cuda.is_available():\n",
    "    model.to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "papermill": {
   "duration": 2514.197238,
   "end_time": "2020-09-24T08:34:15.204249",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-24T07:52:21.007011",
   "version": "2.1.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "016b8f2562b347449d05b296a9cbaa7e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "18ea8f9b8cc3438cb4f582089523985d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "259299955340417eb7a3e052ec870923": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b55b1a1b1793483da7afee4131eafe0d",
        "IPY_MODEL_94ac1e506b4d4a2fa8341204178f2006"
       ],
       "layout": "IPY_MODEL_b5ed9d7e81ab43db9d43b6d70798dc25"
      }
     },
     "25a332fdefd7498f86fd6cf16bfd897c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2821b5f166e441808e0dd941dd01a3f0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2cf5277f2977405cb7ddab79b270715c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4586ad89a9ef48b580236f0313fefba1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "46e180a9f50e45dfb17e64b9480fb3fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2821b5f166e441808e0dd941dd01a3f0",
       "max": 440473133,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_dd3de7c48c624bc1bd953607d4a2b2c9",
       "value": 440473133
      }
     },
     "4c2121f108c64b0e831a287c5a7dd613": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "542993422185464fbf65d882620233aa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "70db27c65ea343bd85ff355ab7851869": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7a72434f89ef466aafc0b8b0d9fd7cb7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "884359b1ffb74deaa19c279dd07b87d6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f206b4d29ea44fd6a1ea83ed59aaaa4f",
        "IPY_MODEL_d17b5e800be04502a5e104060550c0c1"
       ],
       "layout": "IPY_MODEL_2cf5277f2977405cb7ddab79b270715c"
      }
     },
     "8dcfe22cf47a4bd69aefe3bc304c3856": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "94ac1e506b4d4a2fa8341204178f2006": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_25a332fdefd7498f86fd6cf16bfd897c",
       "placeholder": "​",
       "style": "IPY_MODEL_4586ad89a9ef48b580236f0313fefba1",
       "value": " 232k/232k [00:00&lt;00:00, 897kB/s]"
      }
     },
     "b55b1a1b1793483da7afee4131eafe0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8dcfe22cf47a4bd69aefe3bc304c3856",
       "max": 231508,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_18ea8f9b8cc3438cb4f582089523985d",
       "value": 231508
      }
     },
     "b5ed9d7e81ab43db9d43b6d70798dc25": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c0e115ebae1c45b08177209d5887a721": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "c5caa881f7d745f4a6ba57cc442a642b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_46e180a9f50e45dfb17e64b9480fb3fd",
        "IPY_MODEL_ec9524dfccab42518a1f11822348193b"
       ],
       "layout": "IPY_MODEL_ee4323a1ad464c7683b7dfad76f826c6"
      }
     },
     "d17b5e800be04502a5e104060550c0c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_542993422185464fbf65d882620233aa",
       "placeholder": "​",
       "style": "IPY_MODEL_7a72434f89ef466aafc0b8b0d9fd7cb7",
       "value": " 433/433 [00:14&lt;00:00, 29.8B/s]"
      }
     },
     "dd3de7c48c624bc1bd953607d4a2b2c9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "ec9524dfccab42518a1f11822348193b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4c2121f108c64b0e831a287c5a7dd613",
       "placeholder": "​",
       "style": "IPY_MODEL_70db27c65ea343bd85ff355ab7851869",
       "value": " 440M/440M [00:13&lt;00:00, 31.7MB/s]"
      }
     },
     "ee4323a1ad464c7683b7dfad76f826c6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f206b4d29ea44fd6a1ea83ed59aaaa4f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_016b8f2562b347449d05b296a9cbaa7e",
       "max": 433,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c0e115ebae1c45b08177209d5887a721",
       "value": 433
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
